---
title: 'Causal inference with gamma regression or: The problem is with the link function, not the likelihood'
subtitle: 'Part 6 of the GLM and causal inference series.'
author: A. Solomon Kurz
date: '2023-03-28'
excerpt: "In this sixth post of the causal inference series, we compare the Gaussian and gamma likelihoods for zero-bounded, right-skewed continuous data. We also compare the identity and log links for both. As it turns out, the link functions make more a difference for causal inference than the likelihood functions do."
tags:
  - ANCOVA
  - ANOVA
  - ATE
  - CATE
  - causal inference
  - gamma
  - g-computation
  - GLM
  - marginal standardization
  - potential outcomes
  - R
  - RCT
  - tidyverse
  - tutorial
draft: false
layout: single
featured: no
bibliography: /Users/solomonkurz/Dropbox/blogdown5/content/blog/my_blog.bib
biblio-style: apalike
csl: /Users/solomonkurz/Dropbox/blogdown5/content/blog/apa.csl  
link-citations: yes
---

```{r, echo = F, cache = F}
# knitr::opts_chunk$set(fig.retina = 2.5)
options(width = 110)
```

```{r, echo = F}
# save(brm1, file = "fits/brm1.rda")

load("fits/brm1.rda")
```

So far we've seen the difficulties with covaraites, causal inference, and the GLM all seem restricted to discrete models (e.g., binomial, Poisson, negative binomial). In this sixth post of the series, we'll see this issue can extend to models for continuous data, too. As it turns out, it may have less to do with the likelihood function, and more to do with the choice of link function. To highlight the point, we'll compare Gaussian and gamma models, with both the identity and log links.

## We need data

In post, we'll be continuing on with our `horan1971` data set from the [first](https://timely-flan-2986f4.netlify.app/blog/2023-02-06-boost-your-power-with-baseline-covariates/), [second](https://timely-flan-2986f4.netlify.app/blog/2023-02-06-causal-inference-with-potential-outcomes-bootcamp/), and [fourth posts](https://timely-flan-2986f4.netlify.app/blog/2023-02-15-causal-inference-with-bayesian-models/). These data, recall, were transposed from the values displayed in Table 2 from @horan1971coverant. I've saved them as an external `.rda` file in a `/data` subfolder on GitHub ([here](https://github.com/ASKurz/blogdown5/tree/main/content/blog/2023-02-06-causal-inference-with-potential-outcomes-bootcamp/data)). If you don't want to wander over to my GitHub, you can just copy the code from the first post.

```{r, warning = F, message = F}
# packages
library(tidyverse)
library(broom)
library(marginaleffects)
library(ggdist)
library(brms)

# adjust the global theme
theme_set(theme_gray(base_size = 12) +
            theme(panel.grid = element_blank()))

# load the data
load(file = "data/horan1971.rda")

# wrangle a bit
horan1971 <- horan1971 %>% 
  filter(treatment %in% c("delayed", "experimental")) %>% 
  mutate(prec = pre - mean(pre),
         experimental = ifelse(treatment == "experimental", 1, 0))

# what are these, again?
glimpse(horan1971)
```

## Model framework

To my eye, gamma regression is one of the more under-used frameworks in the broader GLM framework. Recall the dependent variable in the `horan1971` data, `post`, is post-intervention weights, measured in pounds. Whether in humans or other animals, body weights are positive continuous values, and their distributions can often show a right skew, particularly whey their means are close to zero. Even though researchers often model data of this kind with the Gaussian likelihood, the gamma distribution can be a great alternative that easily accounts for the lower zero limit and the right skew. To accommodate the lower limit, the inverse link is the canonical link function for gamma regression models [@nelder1972generalized]. To give you a sense, the inverse link works like so:

```{r, fig.width = 5.0125, fig.height = 4.25}
tibble(lbs = seq(from = 0.1, to = 10, by = 0.01)) %>% 
  mutate(`1 / lbs` = 1 / lbs) %>% 
  
  ggplot(aes(x = lbs, y = `1 / lbs`)) +
  geom_hline(yintercept = 1, color = "white") +
  geom_vline(xintercept = 1, color = "white") +
  geom_line() +
  scale_x_continuous(breaks = c(0, 1, 5, 10)) +
  scale_y_continuous(breaks = c(0, 1, 5, 10)) +
  labs(subtitle = "The identity and inverse links for lbs. ranging from 0.1 to 10")
```

The inverse link has an inflection point a 1, and it asymptotes at zero. However, I and others [e.g., @agrestiFoundationsLinearGeneralized2015; @mccullagh1989generalized] have noticed the inverse link has its quirks[^1] for gamma regression, and the identity and log links are often fine alternatives. In this blog post, we'll explore gamma models with both identity and log links. Feel free to explore with the inverse link on your own. The overall results should be similar.

```{r, eval = F, echo = F}
# check
glm(
  data = horan1971,
  family = Gamma,
  post ~ 1 + experimental) %>% 
  avg_comparisons() %>% tidy()

glm(
  data = horan1971,
  family = Gamma(link = "log"),
  post ~ 1 + experimental) %>% 
  avg_comparisons() %>% tidy()
```

We will fit 8 models in total. To warm up, we will start by fitting 4 ANOVA models:

* Gaussian with the identity link,
* Gaussian with the log link,
* gamma with the identity link, and
* gamma with the log link.

We will get to the heart of the post by fitting 4 ANCOVA models:

* Gaussian with the identity link,
* Gaussian with the log link,
* gamma with the identity link, and
* gamma with the log link.

### It's easy with ANOVA.

If we start with the conventional Gaussian likelihood with the identity link as a benchmark, our first ANOVA-type model will follow the form

$$
\begin{align*}
\text{post}_i & \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i & = \beta_0 + \beta_1 \text{experimental}_i,
\end{align*}
$$
where $\beta_0$ is the mean for those on the control condition (i.e., `delayed`) and $\beta_1$ is the difference in the mean for those in the treatment condition (i.e., `experimental`), relative to those in the control.

Our second model will use the log link, instead. Our third model will use the gamma likelihood, but retain the identity link. Our final ANOVA-type model will use the gamma likelihood and the log link. We'll name the models `glm1a` through `glm1d`.

Here's how to fit the models with maximum likelihood by way of the base-**R** `glm()` function. Take special note of the syntax we used in the `family` arguments.

```{r}
# Gaussian, identity link
glm1a <- glm(
  data = horan1971,
  family = gaussian,
  post ~ 1 + experimental)

# Gaussian, log link
glm1b <- glm(
  data = horan1971,
  family = gaussian(link = "log"),
  post ~ 1 + experimental)

# gamma, identity link
glm1c <- glm(
  data = horan1971,
  family = Gamma(link = "identity"),
  post ~ 1 + experimental)

# gamma, log link
glm1d <- glm(
  data = horan1971,
  family = Gamma(link = "log"),
  post ~ 1 + experimental)
```

Review the parameter summaries.

```{r}
summary(glm1a)
summary(glm1b)
summary(glm1c)
summary(glm1d)
```

With both Gaussian and gamma likelihoods, the $\beta_1$ parameter is the same as the estimate for $\tau_\text{ATE}$ when we use the identity link. When we use the log link, however, we can compute the point estimate for $\tau_\text{ATE}$ with the formula

$$\hat{\tau}_\text{ATE} = \exp(\hat \beta_0 + \hat \beta_1) - \exp(\hat \beta_0).$$

Here's how to compute the $\hat{\tau}_\text{ATE}$'s all by hand with `coef()`.

```{r}
likelihoods <- c("Gaussian", "Gamma")
links <- c("identity", "log")

tibble(likelihood = rep(likelihoods, each = 2),
       link       = rep(links, times = 2),
       ate        = c(
         as.double(coef(glm1a)[2]),
         as.double(exp(coef(glm1b)[1] + coef(glm1b)[2]) - exp(coef(glm1b)[1])),
         as.double(coef(glm1c)[2]),
         as.double(exp(coef(glm1d)[1] + coef(glm1d)[2]) - exp(coef(glm1d)[1])))
)
```

At the level of the point estimates, the results are not technically identical, but they're the same up to many decimal points.

```{r, eval = F, echo = F}
# check
as.double(coef(glm1a)[2]) == as.double(exp(coef(glm1b)[1] + coef(glm1b)[2]) - exp(coef(glm1b)[1]))
as.double(coef(glm1a)[2]) - as.double(exp(coef(glm1b)[1] + coef(glm1b)[2]) - exp(coef(glm1b)[1]))

as.double(coef(glm1a)[2]) == as.double(coef(glm1c)[2])
as.double(exp(coef(glm1b)[1] + coef(glm1b)[2]) - exp(coef(glm1b)[1])) == as.double(exp(coef(glm1d)[1] + coef(glm1d)[2]) - exp(coef(glm1d)[1]))
```


If we'd like to use the $\mathbb E (y_i^1) - \mathbb E (y_i^0)$ method for computing the ATE and its measures of uncertainty, like standard errors and 95% intervals, we're better off using the `predictions()` function from the **marginaleffects** package. Here we'll do so for all four models, and wrangle the format a little.

```{r}
bind_rows(
  predictions(glm1a, by = "experimental", hypothesis = "revpairwise"),
  predictions(glm1b, by = "experimental", hypothesis = "revpairwise"),
  predictions(glm1c, by = "experimental", hypothesis = "revpairwise"),
  predictions(glm1d, by = "experimental", hypothesis = "revpairwise")
) %>% 
  data.frame() %>% 
  mutate(likelihood = rep(likelihoods, each = 2),
         link       = rep(links, times = 2)) %>% 
  select(likelihood, link, estimate, std.error, starts_with("conf"))
```

The results are very similar across all summary measures, but they're most notably different for the standard errors and 95% intervals. I don't know that there's an easy way to decide which model is the *best*. The models differ in their underlying assumptions. To my eye, the gamma model with the log link seems pretty attractive; the gamma likelihood naturally accounts for any right skew in the data (there is indeed a little right skew[^2]), and the log link insures the model will never predict non-positive weights. Your preferences may vary.

```{r, eval = F, echo = F}
# check by:

# plot
horan1971 %>% 
  pivot_longer(pre:post) %>% 
  
  ggplot(aes(x = value)) +
  geom_density() +
  facet_wrap(~ name)

# skewness statistic
horan1971 %>% 
  pivot_longer(pre:post) %>% 
  group_by(name) %>% 
  summarise(skew = psych::skew(value))
```

Given how these are all ANOVA-type models (i.e., they have no covariates beyond the experimental grouping variable), we know the case-wise predictions will all be identical when using the $\mathbb E (y_i^1 - y_i^0)$ method for computing our estimates for $\tau_\text{ATE}$. Thus, we might jump directly to the `avg_comparisons()` function, which will automatically average all the case-wise results.

```{r}
bind_rows(
  avg_comparisons(glm1a),
  avg_comparisons(glm1b),
  avg_comparisons(glm1c),
  avg_comparisons(glm1d)
) %>% 
  data.frame() %>% 
  mutate(likelihood = rep(likelihoods, each = 2),
         link       = rep(links, times = 2)) %>% 
  select(likelihood, link, estimate, std.error, starts_with("conf"))
```

By now, hopefully it's no surprise that the results are the same as above when we used the $\mathbb E (y_i^1) - \mathbb E (y_i^0)$  method, above. This is expected behavior when working with ANOVA-type models. This will not be the case, though, with the ANCOVA-type models in the next section. But before we go there, here's a coefficient plot visualization of those $\tau_\text{ATE}$ estimates, and their 95% intervals.

```{r, fig.width = 6, fig.height = 2}
bind_rows(
  avg_comparisons(glm1a),
  avg_comparisons(glm1b),
  avg_comparisons(glm1c),
  avg_comparisons(glm1d)
) %>% 
  data.frame() %>% 
  mutate(likelihood = rep(likelihoods, each = 2) %>% factor(., levels = likelihoods),
         link = rep(links, times = 2) %>% factor(., levels = links)) %>% 

  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = likelihood, color = link)) +
  geom_pointinterval(position = position_dodge(width = -0.6),
                     linewidth = 2, point_size = 2) +
  scale_color_viridis_d("link: ", option = "D", begin = 0.25, end = 0.55, direction = 1) +
  scale_x_continuous(expression(tau[ATE]), expand = expansion(add = 5)) +
  theme(axis.text.y = element_text(hjust = 0),
        legend.position = "top")
```

When you look at the results in the context of a plot like this, the subtle differences in their point estimates and 95% intervals seem trivial, don't they?

### ANCOVA makes it hard.

If we once again use the conventional Gaussian likelihood with the identity link as a benchmark, our first ANCOVA-type model will follow the form

$$
\begin{align*}
\text{post}_i & \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i & = \beta_0 + \beta_1 \text{experimental}_i + \beta_2 \text{prec}_i,
\end{align*}
$$

where $\beta_2$ is the coefficient for our baseline covariate `prec`, which is the mean-centered version of the participant weights (in pounds) before the intervention.

Before we fit the models, we might want to make one more adjustment to the data. The `prec` covariate makes a lot of sense for the models using the identity link. However, it might make more sense to use a mean-centered version of the log of `pre` for the two models using the log link. That way, the pre- and post-intervention weights will both be on the same log scale in the model, and the covariate will still have that desirable mean center. We'll call this new version of the variable `prelc`.

```{r}
horan1971 <- horan1971 %>% 
  mutate(prelc = log(pre) - mean(log(pre)))
```

We might check to make sure both versions of the `pre` covariate have means at zero.

```{r}
horan1971 %>% 
  pivot_longer(ends_with("c")) %>% 
  group_by(name) %>% 
  summarise(m = mean(value))
```

Yep, they're both zero within a very small rounding error.

Okay, here's how to fit the ANCOVA-type models with the `glm()` function. As before, take special note of the `family` syntax.

```{r}
# Gaussian, identity link
glm2a <- glm(
  data = horan1971,
  family = gaussian,
  post ~ 1 + experimental + prec)

# Gaussian, log link
glm2b <- glm(
  data = horan1971,
  family = gaussian(link = "log"),
  post ~ 1 + experimental + prelc)

# gamma, identity link
glm2c <- glm(
  data = horan1971,
  family = Gamma(link = "identity"),
  post ~ 1 + experimental + prec)

# gamma, log link
glm2d <- glm(
  data = horan1971,
  family = Gamma(link = "log"),
  post ~ 1 + experimental + prelc)
```

Check the model summaries.

```{r}
summary(glm2a)
summary(glm2b)
summary(glm2c)
summary(glm2d)
```

The way we interpret our $\beta_1$ coefficients vary by model. For the Gaussian and gamma likelihoods, $\beta_1$ is still an estimator of the ATE, but only when using the identity link function. Here they are:

```{r}
bind_rows(
  tidy(glm2a, conf.int = TRUE), 
  tidy(glm2c, conf.int = TRUE)
) %>% 
  filter(term == "experimental") %>% 
  mutate(likelihood = likelihoods,
         link = rep(links, times = c(2, 0))) %>% 
  select(likelihood, link, estimate, std.error, starts_with("conf"))
```

Even though their numeric summaries are more notably different, now, both models' version of $\beta_1$ is still an estimator of the ATE. The estimators are just founded upon different distributional assumptions. Make your assumptions with care, friends.

The picture differs for the ANCOVA models using the log link. To my knowledge, there is no direct way to compute the ATE from their $\beta_1$ coefficients, alone. The best we could do is use a combination of all three $\beta$ coefficients and tricky exponentiation to compute some version of the CATE. But since the goal of this blog series is to focus on the ATE, we'll avoid that kind of digression for now.

If we wanted to move away from interpreting the $\beta$ coefficients directly, we can set the sole covariate to its mean value $(\bar c)$ to compute the conditional predicted values for the two levels of treatment, and then take their difference:

$$\tau_\text{ATE} = \mathbb E (y_i^1 \mid \bar c) - \mathbb E (y_i^0 \mid \bar c).$$

If we have more than one continuous covariate, we could generalize that equation so that $\mathbf C_i$ is a vector of covariates, and update the equation for the ATE to account for our $\mathbf{\bar C}$ vector to

$$\tau_\text{ATE} = \operatorname{\mathbb{E}} \left (y_i^1 \mid \mathbf{\bar C} \right) - \operatorname{\mathbb{E}} \left (y_i^0 \mid \mathbf{\bar C} \right).$$

This approach will only work, however, for our models which used the identity link. This will be a complete failure for the models which used the log link. Here we compute the results for all four models with `predictions()`, and reformat a little to make the output nicer.

```{r}
# first set the predictor grid
nd <- tibble(experimental = 0:1,
             prec         = 0,
             prelc        = 0)

# compute
bind_rows(
  predictions(glm2a, newdata = nd, by = "experimental", hypothesis = "revpairwise"),
  predictions(glm2b, newdata = nd, by = "experimental", hypothesis = "revpairwise"),
  predictions(glm2c, newdata = nd, by = "experimental", hypothesis = "revpairwise"),
  predictions(glm2d, newdata = nd, by = "experimental", hypothesis = "revpairwise")
) %>% 
  data.frame() %>%
  mutate(likelihood = rep(likelihoods, each = 2) %>% factor(., levels = likelihoods),
         link = rep(links, times = 2) %>% factor(., levels = links),
         estimand = rep(c("ATE", "CATE"), times = 2)) %>% 
  select(likelihood, link, estimand, estimate, std.error, starts_with("conf")) %>%
  mutate_if(is.double, round, digits = 3)
```

This can be hard to catch because the estimates are all so similar, but slightly different. The results in the first and third rows are for the ATE. However, the results in the second and fourth rows are for different versions of the CATE. The second row is the CATE for cases with a mean value for `pre`. The fourth row is the CATE for cases with a mean value for log-transformed `pre`. Here are what those mean values are on the `pre` scale.

```{r}
horan1971 %>% 
  summarise(mean_pre = mean(pre),
            exponentiated_mean_log_pre = mean(log(pre)) %>% exp()) %>% 
  pivot_longer(everything())
```

Even though these look like integer values, that's only because the output was rounded in the process of rendering this file into the format you see on the blog. Both summary numbers have a log trail of decimal digits.

Anyway, whether you're using the Gaussian or gamma likelihood, you *cannot* use the $\mathbb E (y_i^1 \mid \bar c) - \mathbb E (y_i^0 \mid \bar c)$ method to compute the ATE if you use the log link. If you prefer that method, you can only compute some version of the CATE.

Regardless of the link function, it's the $\mathbb E (y_i^1 - y_i^0 \mid c_i)$ method that will return an estimate for the ATE across ANCOVA-type models. That is, we compute each case's $y_i^1$ and $y_i^0$ estimate, conditional on their baseline covariate value, take the difference in those estimates, and average across all cases. Before we do all that in one step with the handy `avg_comparisons()` function, it's worth first showing the case-level predictions and their contrasts in a plot. Here are the case-level predictions from the four ANCOVA models.

```{r, fig.width = 8, fig.height = 5.5}
# update the predictor grid to include all versions of the baseline covariate pre
nd <- horan1971 %>% 
  select(sn, prec, prelc, pre) %>% 
  expand_grid(experimental = 0:1)

# compute the counterfactual predictions for each case
bind_rows(
  predictions(glm2a, newdata = nd, by = c("sn", "experimental", "pre")),
  predictions(glm2b, newdata = nd, by = c("sn", "experimental", "pre")),
  predictions(glm2c, newdata = nd, by = c("sn", "experimental", "pre")),
  predictions(glm2d, newdata = nd, by = c("sn", "experimental", "pre"))
) %>% 
  # wrangle
  data.frame() %>% 
  mutate(y = ifelse(experimental == 0, "hat(italic(y))^0", "hat(italic(y))^1")) %>% 
  mutate(fit = rep(str_c("glm2", letters[1:4]), each = n() / 4)) %>% 
  mutate(likelihood = rep(likelihoods, each = n() / 2) %>% factor(., levels = likelihoods),
         link = rep(c(links, links), each = n() / 4) %>% factor(., levels = links)) %>% 
  
  # plot!
  ggplot(aes(x = estimate, y = reorder(sn, estimate))) +
  geom_interval(aes(xmin = conf.low, xmax = conf.high, color = y),
                    position = position_dodge(width = 0.2),
                    size = 1/5) +
  geom_point(aes(color = y, shape = y),
             size = 2) +
  scale_color_viridis_d(NULL, option = "A", begin = .3, end = .6,
                        labels = scales::parse_format()) +
  scale_shape_manual(NULL, values = c(20, 18),
              labels = scales::parse_format()) +
  scale_y_discrete(breaks = NULL) +
  labs(subtitle = "counterfactual predictions",
       x = "post",
       y = "sn (ranked)") +
  coord_cartesian(xlim = c(120, 200)) +
  theme(legend.background = element_blank(),
        legend.position = c(.9, .85)) +
  facet_grid(link ~ likelihood, labeller = label_both)
```

On the whole, the case-level counterfactual predictions are very similar across models. They aren't exactly the same, though. This will be easier to see when we compare their contrasts.

```{r, fig.width = 8, fig.height = 5.5}
bind_rows(
  comparisons(glm2a, variables = "experimental", by = "sn"),
  comparisons(glm2b, variables = "experimental", by = "sn"),
  comparisons(glm2c, variables = "experimental", by = "sn"),
  comparisons(glm2d, variables = "experimental", by = "sn")
) %>% 
  data.frame() %>% 
  mutate(fit = rep(str_c("glm2", letters[1:4]), each = n() / 4)) %>% 
  mutate(likelihood = rep(likelihoods, each = n() / 2) %>% factor(., levels = likelihoods),
         link = rep(c(links, links), each = n() / 4) %>% factor(., levels = links)) %>% 
  
  ggplot(aes(x = estimate, y = reorder(sn, estimate))) +
  geom_vline(xintercept = 0, color = "white") +
  geom_interval(aes(xmin = conf.low, xmax = conf.high),
                size = 1/5) +
  geom_point() +
  scale_y_discrete(breaks = NULL) +
  labs(subtitle = "treatment effects",
       x = expression(hat(tau)[italic(i)]~("i.e., "*hat(italic(y))[italic(i)]^1-hat(italic(y))[italic(i)]^0)),
       y = NULL) +
  xlim(-40, 40) +
  facet_grid(link ~ likelihood, labeller = label_both)
```

Regardless of the likelihood function, the models that used the identity link return identical $\tau_i$ estimates for all cases. The log link, however, returned slightly different $\tau_i$ estimates across the cases. The complication lies with the link function. Happily, all models return an estimate for $\tau_\text{ATE}$ when we use the $\mathbb E (y_i^1 - y_i^0 \mid c_i)$ method by way of the `avg_comparisons()` function.

```{r}
bind_rows(
  avg_comparisons(glm2a, variables = "experimental"),
  avg_comparisons(glm2b, variables = "experimental"),
  avg_comparisons(glm2c, variables = "experimental"),
  avg_comparisons(glm2d, variables = "experimental")
) %>% 
  data.frame()%>%
  mutate(likelihood = rep(likelihoods, each = 2) %>% factor(., levels = likelihoods),
         link = rep(links, times = 2) %>% factor(., levels = links),
         estimand = "ATE") %>% 
  select(likelihood, link, estimand, estimate, std.error, starts_with("conf")) %>%
  mutate_if(is.double, round, digits = 3)
```

Even though the point estimates and their measures of uncertainty differ a bit, these are all estimators of the $\tau_\text{ATE}$, each based on slightly different model assumptions. Here's what they all look like in a coefficient plot.

```{r, fig.width = 6, fig.height = 2}
bind_rows(
  avg_comparisons(glm2a, variables = "experimental"),
  avg_comparisons(glm2b, variables = "experimental"),
  avg_comparisons(glm2c, variables = "experimental"),
  avg_comparisons(glm2d, variables = "experimental")
) %>% 
  data.frame() %>% 
  mutate(likelihood = rep(likelihoods, each = 2) %>% factor(., levels = likelihoods),
         link = rep(links, times = 2) %>% factor(., levels = links)) %>% 

  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = likelihood, color = link)) +
  geom_pointinterval(position = position_dodge(width = -0.6),
                     linewidth = 2, point_size = 2) +
  scale_color_viridis_d("link: ", option = "D", begin = 0.25, end = 0.55, direction = 1) +
  scale_x_continuous(expression(tau[ATE]), expand = expansion(add = 5)) +
  theme(axis.text.y = element_text(hjust = 0),
        legend.position = "top")
```

*Which one is right?* I can't answer that for you. They're all based on models with different underlying assumptions. Make your modeling assumptions with care, friends. Me, I like the gamma model with the log link.

## Causal inference with Bayesian gamma regression

I'm not going to repeat all of our frequentist analyses as a Bayesian because that would make for an overly ponderous post. But I do think it's reasonable to give a brief walk-through with a single ANCOVA model of the form

$$
\begin{align*}
\text{post}_i & \sim \operatorname{Gamma}(\mu_i, \alpha) \\
\log(\mu_i) & = \beta_0 + \beta_1 \text{experimental}_i + \beta_2 \text{prelc}_i \\
\beta_0 & \sim \operatorname{Normal}(5.053056, 0.09562761) \\
\beta_1 & \sim \operatorname{Normal}(0, 0.25) \\
\beta_2 & \sim \operatorname{Normal}(0.75, 0.25) \\
\alpha & \sim \operatorname{Gamma}(0.01, 0.01).
\end{align*}
$$

Note that with **brms**, the gamma likelihood is parameterized in terms of the mean $(\mu)$ and the shape $(\alpha)$. If desired, we could compute the more familiar scale parameter $(\theta)$ with the equation

$$\theta = \frac{\mu}{\alpha}.$$

Anyway, my priors may look oddly specific. Let me walk them out. 

Recall that in the [fourth post](https://timely-flan-2986f4.netlify.app/blog/2023-02-15-causal-inference-with-bayesian-models/), we used $\operatorname{Normal}(156.5, 15)$ as the prior for the $\beta_0$ intercept in the Gaussian model with the conventional identity link. Since we're now using the log link, we need to set our priors with the conditional mean on the log scale. Did you know that if you take the log of a normal distribution, you end up with a lognormal distribution? The lognormal is a 2-parameter distribution over the positive real values, which has a nice right skew. The lognormal is odd in that its two parameters, $\mu$ and $\sigma$, are the population mean and standard deviation of the normal distribution you'd get after log-transforming the lognormal distribution. The math gets a little hairy, but if you wanted a lognormal distribution with a given mean and standard deviation on its own scale, you'd need to use the equations

$$
\begin{align*}
\mu & = \log\left ( \bar y \Bigg / \sqrt{\frac{s^2}{\bar y^2} + 1} \right), \text{and} \\
\sigma & = \sqrt{\log \left(\frac{s^2}{\bar y^2} + 1 \right)},
\end{align*}
$$

where $\bar y$ is our desired mean and $s$ is our desired SD. So what if we wanted a lognormal distribution that had a mean of 156.5 and a standard deviation of 15, to resemble the prior we used back in post #4? We could use those equations with the following code:

```{r}
m <- 156.5  # desired mean
s <- 15     # desired SD

# use the equations
mu    <- log(m / sqrt(s^2 / m^2 + 1))
sigma <- sqrt(log(s^2 / m^2 + 1))

# what are the lognormal parameter values?
mu; sigma
```

Here's what that distribution looks like.

```{r, fig.width = 5.75, fig.height = 3}
prior(lognormal(5.053056, 0.09562761)) %>% 
  parse_dist() %>% 
  
  ggplot(aes(xdist = .dist_obj, y = prior)) + 
  stat_halfeye(.width = c(.5, .95), p_limits = c(.0001, .9999)) +
  scale_y_discrete(NULL, breaks = NULL, expand = expansion(add = 0.1)) +
  labs(title = "Lognormal(5.053056, 0.09562761)",
       subtitle = "A normal prior on the log link is like a lognormal prior on the identity link.",
       x = expression(exp(italic(p)(beta[0])))) +
  coord_cartesian(xlim = c(100, 250))
```

Thus, if we use a $\operatorname{Normal}(5.053056, 0.09562761)$ prior for $\beta_0$ on the log scale, that's the equivalent of using a lognormal prior with a mean of 156.5 and a standard deviation of 15 on the identity scale.

Even though the $\operatorname{Normal}(0, 0.25)$ prior might seem tight for our $\beta_1$ coefficient for the group difference, keep in mind that difference is on the log scale. Thus, we're putting about 95% of our prior mass on a half-log difference in either direction. For example, if we presume the control group will indeed have an average weight of 156.5 pounds, the $\operatorname{Normal}(0, 0.25)$ prior puts 95% of the prior mass between these two weights for those in the experimental condition:

```{r}
exp(5.053056 + c(-0.5, 0.5))
```

That's a wide spread, and frankly it suggests we could easily justify an even more conservative prior.

As to our $\operatorname{Normal}(0.75, 0.25)$ prior for $\beta_2$, this is suggesting the pre- and post-intervention weights scale close together, even when they're on the log scale. In my experience, this is a good rule of thumb for behavioral data. If you're not as confident as I am, adjust your prior accordingly.

The $\operatorname{Gamma}(0.01, 0.01)$ prior for the shape parameter $\alpha$ is the `brm()` default. You might use the `get_prior()` function to check this for yourself. If you're going to be fitting a lot of Bayesian gamma regression models, you're going to want to learn how to go beyond the default prior for your $\alpha$ parameters. Since this is just a small point in a much larger story, I'm not going to dive much deeper into the topic, here. But if you wanted to start somewhere, keep in mind that when a gamma distribution's $\mu = \alpha$, the population mean and variance are the same[^3]; and with $\mu$ held constant, larger values of $\alpha$ make for *smaller* variances[^4].

```{r, fig.width = 5.75, fig.height = 3, eval = F, echo = F}
# check different priors for alpha (shape)

m <- 156.5  # desired mean
s <- sqrt(m)  # desired SD
# s <- sqrt(m) * 2  # desired SD

# use the equations
mu    <- log(m / sqrt(s^2 / m^2 + 1))
sigma <- sqrt(log(s^2 / m^2 + 1))

# what are the parameter values?
mu; sigma

prior(lognormal(5.049871, 0.07980882)) %>%
# prior(lognormal(5.040437, 0.1588645)) %>%  # SD twice the square of the mean
  parse_dist() %>% 
  
  ggplot(aes(xdist = .dist_obj, y = prior)) + 
  stat_halfeye(.width = c(.5, .95), p_limits = c(.0001, .9999)) +
  scale_y_discrete(NULL, breaks = NULL, expand = expansion(add = 0.1)) +
  labs(title = "Logormal(5.049871, 0.07980882)",
       subtitle = "A normal prior on the log link is like a lognormal prior on the identity link.",
       x = expression(italic(p)(alpha))) +
  coord_cartesian(xlim = c(100, 250))

horan1971 %>% 
  group_by(experimental) %>% 
  summarise(m = mean(post),
            v = var(post),
            s = sd(post))
```

```{r, eval = F, echo = F}
get_prior(
  data = horan1971,
  family = Gamma(link = "log"),
  post ~ 0 + Intercept + experimental + prelc
)
```

Okay, here's how to fit the model with `brm()`.

```{r, eval = F}
# Bayesian gamma ANCOVA, with the log link
brm1 <- brm(
  data = horan1971,
  family = Gamma(link = "log"),
  post ~ 0 + Intercept + experimental + prelc,
  prior = prior(normal(5.053056, 0.09562761), class = b, coef = Intercept) +
    prior(normal(0, 0.25), class = b, coef = experimental) +
    prior(normal(0.75, 0.25), class = b, coef = prelc) +
    prior(gamma(0.01, 0.01), class = shape),  # the brms default
  cores = 4, seed = 6
)
```

Here we'll compare the parameter summary for our Bayesian model to its maximum likelihood analogue.

```{r}
summary(glm2d)  # maximum likelihood
print(brm1)  # Bayes via HMC
```

The results for the $\beta$ parameters are very similar.

Since we're in Bayesian mode, we might do a posterior-predictive check to make sure the model does an okay job simulating data that resemble the sample data.

```{r, fig.width = 7, fig.height = 3, message = F}
set.seed(6)
pp_check(brm1, type = "dens_overlay_grouped", group = "experimental", ndraws = 100) +
  ggtitle("Posterior-predictive check (overlaid densities)")
```

On the whole, the model did a pretty okay job capturing the skewed distributions of the original sample data. How'd we do capturing the conditional means and standard deviations, by experimental group?

```{r, fig.width = 6, fig.height = 3, message = F}
set.seed(6)
pp_check(brm1, type = "stat_grouped", group = "experimental", stat = "mean") +
  ggtitle("Posterior-predictive check (conditional means)") +
  coord_cartesian(xlim = c(143, 162))

set.seed(6)
pp_check(brm1, type = "stat_grouped", group = "experimental", stat = "sd") +
  ggtitle("Posterior-predictive check (conditional SD's)") +
  coord_cartesian(xlim = c(9, 26))
```

Our model did a great job.

With our Bayesian gamma ANCOVA, with the log link, the easiest way to compute our posterior for the ATE is with the `avg_comparisons()` function from **marginaleffects**.

```{r}
avg_comparisons(brm1, variables = "experimental")
```

Recall that by default, the measure of central tendency in the `Estimate` column is the median for Bayesian models. If we wanted to get a look at the full posterior distribution for $\tau_\text{ATE}$, we could tack on the `posterior_draws()` function from **marginaleffects**, and then plot or summarize as desired. Here's what looks like for making a half-eye plot.

```{r, fig.width = 5, fig.height = 3, message = F}
avg_comparisons(brm1, variables = "experimental") %>% 
   posterior_draws() %>% 
  
  ggplot(aes(x = draw)) +
  stat_halfeye(point_interval = mean_qi, .width = c(.5, .95)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(title = "Bayesians like to show their posteriors.",
       x = expression(tau[ATE]))
```

It's a thing of beauty, isn't it? For more details on how to use **marginaleffects** functions to work with `brm()` models, check out Arel-Bundock's [-@arelBundock2023BayesianAnalysis] vignette, *Bayesian analysis with brms*.

## Recap

In this post, some of the main points we covered were:

* The gamma likelihood is a fine option for modeling right-skewed continuous variables with a lower limit of zero.
* The inverse function is the canonical link for gamma regression, but the log and identity links are popular alternatives.
* When you use the identity link for either the Gaussian or the gamma ANOVA, the $\beta_1$ parameter, the $\mathbb E (y_i^1 - y_i^0)$ method, and the $\mathbb E (y_i^1) - \mathbb E (y_i^0)$ method are all valid estimators of $\tau_\text{ATE}$.
* When you use the log link for either the Gaussian or the gamma ANOVA, only the $\mathbb E (y_i^1 - y_i^0)$ method and the $\mathbb E (y_i^1) - \mathbb E (y_i^0)$ method are all valid estimators of $\tau_\text{ATE}$. 
* When you use the identity link for either the Gaussian or the gamma ANCOVA, the $\beta_1$ parameter, the $\mathbb E (y_i^1 - y_i^0 \mid c_i)$ method, and the $\mathbb E (y_i^1 \mid \bar c) - \mathbb E (y_i^0 \mid \bar c)$ method are all valid estimators of $\tau_\text{ATE}$.
* When you use the log link for either the Gaussian or the gamma ANCOVA, only the $\mathbb E (y_i^1 - y_i^0 \mid c_i)$ method can return a valid estimate for $\tau_\text{ATE}$.

Until next time, happy modeling, friends!

## Session info

```{r}
sessionInfo()
```

## References

[^1]: The language of "quirks" is my own. The inverse link has the technical limitation that it will not insure on its own that the model will not return negative predictions, which is an insight you can find in the technical literature [e.g., @mccullagh1989generalized]. In addition, I have personally found the inverse link can cause estimation difficulties with both frequentist (`glm()`) and Bayesian (`brm()`) software. The log link *just works*, friends. Use the log link for gamma.

[^2]: You don't have to believe me. Check it for yourself. You might do a visual check with a histogram or density plot. Or you could compute the sample skewness statistic with the `skew()` function from the **psych** package [@R-psych].

[^3]: *Why would I assume the mean and variance would be the same?* you ask. Well, you might not. But bear in mind that the popular likelihood for unbounded counts, the Poisson, assumes the mean and variance are the same. Granted, the Poisson likelihood often underestimates the variance in real-world sample data, and we might not expect our positive-real skewed continuous data will behave like unbounded counts. But you have to start somewhere, friends. Why not appeal to one of the devils you already know?

[^4]: Within the context of a fixed $\mu$, you might think of $\alpha$ as a *concentration* parameter. The higher the $\alpha$, the more concentrated the distribution gets around the mean.

```{r, eval = F, echo = F}
text <- bind_rows(
  avg_comparisons(glm2c, variables = "experimental"),
  avg_comparisons(glm2d, variables = "experimental")
) %>% 
  data.frame() %>% 
  mutate(likelihood = rep(likelihoods, times = c(0, 2)) %>% factor(., levels = likelihoods),
         link = factor(links, levels = links))

bind_rows(
  avg_comparisons(glm2a, variables = "experimental"),
  avg_comparisons(glm2b, variables = "experimental"),
  avg_comparisons(glm2c, variables = "experimental"),
  avg_comparisons(glm2d, variables = "experimental")
) %>% 
  data.frame() %>% 
  mutate(likelihood = rep(likelihoods, each = 2) %>% factor(., levels = likelihoods),
         link = rep(links, times = 2) %>% factor(., levels = links)) %>% 

  ggplot(aes(x = estimate, y = likelihood, color = link)) +
  geom_pointinterval(aes(xmin = conf.low, xmax = conf.high),
                     position = position_dodge(width = -0.7),
                     linewidth = 2, point_size = 2) +
  geom_text(data = text,
            aes(x = conf.high + 0.2, label = link),
            position = position_dodge(width = -0.7),
            hjust = 0) +
  scale_color_viridis_d("link: ", option = "D", begin = 0.25, end = 0.55, direction = 1) +
  scale_x_continuous(expression(tau[ATE]), expand = expansion(add = 4)) +
  labs(title = "ATE by likelihood and link function",
       subtitle = "For ANCOVA models, the problem is with the\nlink function, not with the likelihood.",
       y = NULL) +
  theme_linedraw() +
  theme(axis.text.y = element_text(hjust = 0),
        legend.position = "none",
        panel.grid = element_blank(),
        plot.title.position = "plot")

ggsave("coefficients-featured.jpg", width = 3.6, height = 3.5, units = "in")
```



