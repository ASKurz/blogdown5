---
title: 'Boost your power with baseline covariates'
subtitle: 'Part 1 of the GLM and causal inference series.'
author: A. Solomon Kurz
date: '2023-02-06'
excerpt: "This is the first post in a series on causal inference. Our ultimate goal is to learn how to analyze data from true experiments, such as RCT's, with various likelihoods from the generalized linear model (GLM), and with techniques from the contemporary causal inference literature. In this post, we review how baseline covariates help us compare our experimental conditions."

tags:
  - ANCOVA
  - ANOVA
  - causal inference
  - GLM
  - power
  - R
  - RCT
  - tidyverse
  - tutorial
draft: false
layout: single
featured: no
bibliography: /Users/solomonkurz/Dropbox/blogdown5/content/blog/my_blog.bib
biblio-style: apalike
csl: /Users/solomonkurz/Dropbox/blogdown5/content/blog/apa.csl  
link-citations: yes
---

## What?

This is the first post in a series on causal inference. Our ultimate goal is to learn how to analyze data from true experiments, such as RCT's, with various likelihoods from the generalized linear model (GLM), and with techniques from the contemporary causal inference literature. We'll do so both as frequentists and as Bayesians.

I'm writing this series because, even though I learned a lot about data analysis and research design during my PhD, I did not receive training in the contemporary causal inference literature. Some of my recent data-analysis projects have made it very clear that I need to better understand this framework, and how it works within the broader GLM paradigm. As it turns out, there are some tricky twists and turns, and my hope is this series will help me better clarify this framework for myself, and help bring it to some of y'all's attention, too.

In this first installment, we'll review a long-established insight from the RCT literature: baseline covariates help us compare our experimental conditions.

### I make assumptions.

This series is an applied tutorial more so than an introduction. I'm presuming you have a passing familiarity with the following:

You should have a basic grounding in group-based experimental design. Given my background in clinical psychology, I recommend @shadish2002Experimental or @kazdin2017ResearchDesign. You might also check out @taback2022DesignAndAnalysis, and its free companion website at [https://designexptr.org/index.html](https://designexptr.org/index.html).

You'll want to be familiar with single-level regression, from the perspective of the GLM. For frequentist resources, I recommend the texts by @ismay2022StatisticalInference and @roback2021beyond. For the Bayesians in the room, I recommend the texts by Gelman and colleagues [-@gelmanRegressionOtherStories2020], Kruschke [-@kruschkeDoingBayesianData2015], or McElreath [-@mcelreathStatisticalRethinkingBayesian2015; -@mcelreathStatisticalRethinkingBayesian2020].

Though I don't expect familiarity with contemporary causal inference from the outset, you'll probably want to read up on the topic at some point. When you're ready, consider texts like @brumback2022Fundamentals, @hernan2020CausalInference, or @imbensCausalInferenceStatistics2015. If you prefer freely-accessible ebooks, check out @cunningham2021causal.

All code will be in **R** [@R-base]. Data wrangling and plotting will rely heavily on the **tidyverse** [@R-tidyverse; @wickhamWelcomeTidyverse2019] and **ggdist** [@R-ggdist]. Bayesian models will be fit with [**brms**](https://github.com/paul-buerkner/brms) [@R-brms; @burknerBrmsPackageBayesian2017; @burknerAdvancedBayesianMultilevel2018].
We will post process our models with help packages such as **broom** [@R-broom], **marginaleffects** [@R-marginaleffects], and [**tidybayes** package](https://mjskay.github.io/tidybayes/) [@R-tidybayes].

Load the primary **R** packages and adjust the global plotting theme.

```{r, warning = F, message = F}
library(tidyverse)
library(broom)

theme_set(theme_gray(base_size = 12) +
            theme(panel.grid = element_blank()))
```

## We need data

In this post, we'll be borrowing data from @horan1971coverant, *Coverant conditioning through a self-management application of the Premack principle: Its effect on weight reduction*. We don't have the original data file, being this paper was from the 70's and all. However, Horan and Johnson were open-data champions and then listed all the values for their primary outcomes in Table 2 (p. 246). Here we transcribe those data into a tibble named `horan1971`.

```{r}
horan1971 <- tibble(
  sl = c(letters[1:22], letters[1:20], letters[1:19], letters[1:19]),
  sn = 1:80,
  treatment = factor(rep(1:4, times = c(22, 20, 19, 19))),
  pre = c(149.5, 131.25, 146.5, 133.25, 131, 141, 145.75, 146.75, 172.5, 156.5, 153, 136.25, 148.25, 152.25, 167.5, 169.5, 151.5, 165, 144.25, 167, 195, 179.5,
          127, 134, 163.5, 155, 157.25, 121, 161.25, 147.25, 134.5, 121, 133.5, 128.5, 151, 141.25, 164.25, 138.25, 176, 178, 183, 164,
          149, 134.25, 168, 116.25, 122.75, 122.5, 130, 139, 121.75, 126, 159, 134.75, 140.5, 174.25, 140.25, 133, 171.25, 198.25, 141.25,
          137, 157, 142.25, 123, 163.75, 168.25, 146.25, 174.75, 174.5, 179.75, 162.5, 145, 127, 146.75, 137.5, 179.75, 168.25, 187.5, 144.5),
  post = c(149, 130, 147.75, 139, 134, 145.25, 142.25, 147, 158.25, 155.25, 151.5, 134.5, 145.75, 153.5, 163.75, 170, 153, 178, 144.75, 164.25, 194, 183.25,
           121.75, 132.25, 166, 146.5, 154.5, 114, 148.25, 148.25, 133.5, 126.5, 137, 126.5, 148.5, 145.5, 151.5, 128.5, 176.5, 170.5, 181.5, 160.5,
           145.5, 122.75, 164, 118.5, 122, 125.5, 129.5, 137, 119.5, 123.5, 150.5, 125.75, 135, 164.25, 144.5, 135.5, 169.5, 194.5, 142.5,
           129, 146.5, 142.25, 114.5, 148.25, 161.25, 142.5, 174.5, 163, 160.5, 151.25, 144, 135.5, 136.5, 145.5, 185, 174.75, 179, 141.5)) %>% 
  mutate(treatment = factor(treatment, labels = c("delayed", "placebo", "scheduled", "experimental")))

# what is this?
glimpse(horan1971)
```

Horan and Johnson randomly assigned 80 women who were between "20 per cent and 30 per cent overweight" into four groups for weight loss. In the `horan1971` data, these four groups are differentiated in the `treatment` column, which is coded

* `delayed`, a "delayed treatment control" (i.e., wait-list control), the members of which received an active treatment after the study;
* `placebo`, a minimalist intervention where particulates were given basic information about nutrition and weight-loss strategies;
* `scheduled`, an active treatment that added a cognitive element to the information from the `placebo` group; and
* `experimental`, which added a full behavioral element (based on the Premack principle[^1]) to the `placebo` intervention.

Those of you who aren't in clinical psychology might wonder how we can call an information-based intervention a *placebo*. As it turns out, information-based interventions aren't great at prompting lasting behavior change. You need to do more than preach.

Anyway, the focal variable of this intervention is body weight, measured in pounds. The `pre` column has each woman's pre-intervention body weight and the `post` column has their post-intervention weights. As is typical in a weigh-loss study, the goal is to have one or more active interventions show lower average weights at the end of the study (i.e., lower values for `post`). 

```{r, evall = F, echo = F}
save(horan1971, file = "data/horan1971.rda")
```

### Subset.

Though we'll eventually analyze the full data set with all four groups, it'll be easier to cover the basics of this material if we focus on only two of the groups. Here subset the data to only include the cases from the `delayed` and `experimental` groups.

```{r}
horan1971 <- horan1971 %>% 
  filter(treatment %in% c("delayed", "experimental"))
```

Now prove we've reduced the data properly.

```{r}
horan1971 %>% 
  count(treatment)
```

### Exploratory data analysis.

To get a sense of the data, here are what the post-intervention weights (`post`) look for the two treatment groups in our data subset.

```{r, fig.width = 6, fig.height = 3}
horan1971 %>%  
  ggplot(aes(x = post)) +
  geom_histogram(binwidth = 5) +
  xlab("post-treatment weight (lbs)") +
  facet_wrap(~ treatment, labeller = label_both)
```

At a basic level, our primary research question is: Which group is better for weight loss? As we move along in this blog series, we'll find ways to refine that question. In the meantime, here are the basic descriptive statistics.

```{r}
horan1971 %>% 
  group_by(treatment) %>% 
  summarise(mean = mean(post),
            sd = sd(post),
            n = n(),
            percent_missing = mean(is.na(post)) * 100)
```

Happily, we have no missing data.

### Center the covariate.

To make some of the models more interpretable, we'll want to make a mean-centered version of pre-intervention weight (`pre`). We'll name the new variable `prec`.

```{r}
horan1971 <- horan1971 %>% 
  # make a mean-centered version of pre
  mutate(prec = pre - mean(pre))
```

### We need dummies.

We don't technically have to do this, but it might help some readers if we break up the four-category `treatment` variable into four dummy variables.

```{r}
horan1971 <- horan1971 %>% 
  mutate(delayed      = ifelse(treatment == "delayed", 1, 0),
         placebo      = ifelse(treatment == "placebo", 1, 0),
         scheduled    = ifelse(treatment == "scheduled", 1, 0),
         experimental = ifelse(treatment == "experimental", 1, 0))
```

Here's how the four dummies relate to `treatment`.

```{r}
horan1971 %>% 
  distinct(treatment, delayed, placebo, scheduled, experimental)
```

In our subsetted version of the `horan1971` data, we have all `0`'s for the `placebo` and `scheduled` dummies. In the analyses to come, our focal variable will be `experimental`, which will make the `delayed` group the default.

## Models

Our friends the methodologists and statisticians have spent the better part of the past 100 years in debate over how one might analyze data of this kind. We're not going to cover all the issues and controversies, here, but you can find your way into the literature with works like @bodner2018Detecting, @oConnell2017methods, or @vanBreukelen2013ancova. A lot of the debate has been in the context of the ordinary least squares (OLS) framework, which will be a handy place for us to start.

In this post, we'll practice analyzing these data in two basic ways: 

1. The "ANOVA" model[^2]
2. The "ANCOVA" model

I hate these names, but they have historical precedents and I hate all the alternative names, too. As we'll see, the ANCOVA model is generally the way to go.

### The simple ANOVA model.

A classical statistical approach to comparing the means of two groups is with a $t$-test or a one-way ANOVA. On this website we like regression and it turns out the regression-model alternative to the classical approaches is

$$
\begin{align*}
\text{post}_i & \sim \operatorname{Gaussian}(\mu_i, \sigma) \\
\mu_i & = \beta_0 + \beta_1 \text{experimental}_i,
\end{align*}
$$

where $\beta_0$ is the mean for those on the control condition (i.e., `delayed`) and $\beta_1$ is the difference in the mean for those in the treatment condition (i.e., `experimental`), relative to those in the control.

Though we'll eventually analyze these data as Bayesians, I think it'll be best if we start with the simpler frequentist OLS paradigm. Thus, here's how to fit this model with the good-old `lm()` function.

```{r}
# fit the ANOVA-type model with OLS
fit1 <- lm(
  data = horan1971,
  post ~ 1 + experimental
)

# summarize
summary(fit1)
```

We can get a nice parameter summary with 95% confidence intervals with the `broom::tidy()` function. Here we'll focus on the $\beta_1$ parameter, which allows us to formally compare the means of the two groups.

```{r}
tidy(fit1, conf.int = TRUE) %>% 
  slice(2) %>% 
  mutate_if(is.double, round, digits = 2)
```

The 95% CIs are wide and uncertain, as we'd expect from a study with a modest sample size. But the point estimate is negative, suggesting the active treatment condition resulted in greater weight loss, on average, than the wait-list control condition.

### The ANCOVA model.

The so-called ANCOVA model adds important baseline covariates to the model. In the case of the `horan1971` data, the only baseline covariate available is `pre`, which is the pre-treatment measure of weight. As it turns out, the pre-treatment measure of an outcome variable is often one of the best choices of covariates you could ask for, given that pre-treatment measurements tend to have strong correlations with post-treatment measurements[^3]. In our case, `pre` and `post` are correlated above .9 in both groups.

```{r}
horan1971 %>% 
  group_by(treatment) %>% 
  summarise(r = cor(pre, post))
```

The correlation is the same whether we use `pre` or the mean-centered version of the variable, `prec`.

Anyway, the ANCOVA model adds one or more baseline covariates to the ANOVA model. For our data, this results in the statistical formula

$$
\begin{align*}
\text{post}_i & \sim \operatorname{Gaussian}(\mu_i, \sigma) \\
\mu_i & = \beta_0 + \beta_1 \text{experimental}_i + {\color{firebrick}{\beta_2 \text{pre}_i}},
\end{align*}
$$

where $\beta_2$ is the coefficient for our baseline covariate `pre`. Now if you've taken a good introductory course on linear regression, you'll know simply adding `pre` to the model will have an adverse consequence for the intercept, $\beta_0$. This is because `pre` is how heavy the participants were at baseline, which tended to be around 155 pounds or so, on average.

```{r}
horan1971 %>% 
  summarise(pre_mean = mean(pre),
            pre_sd = sd(pre),
            pre_min = min(pre))
```

Thus, the intercept $\beta_0$ is now the expected value for those in the wait-list control condition, when they weigh 0 pounds. But none of our adult participants weigh zero pounds, or even near zero pounds. So to make the intercept more meaningful, we can fit an alternative version of the model with the mean-centered of the covariate, `prec`,

$$
\begin{align*}
\text{post}_i & \sim \operatorname{Gaussian}(\mu_i, \sigma) \\
\mu_i & = \beta_0 + \beta_1 \text{experimental}_i + {\color{blueviolet}{\beta_2 \text{prec}_i}},
\end{align*}
$$

where now the intercept $\beta_0$ has the more meaningful interpretation of the expected value for those in the wait-list control group, who have a sample-average weight of about 154 pounds. For the sake of pedagogy, we'll fit the model with the non-centered `pre` covariate (`fit2`) and the centered `prec` covariate (`fit3`).

```{r}
# fit with the non-centered `pre` covariate
fit2 <- lm(
  data = horan1971,
  post ~ 1 + experimental + pre
)

# fit with the centered `prec` covariate
fit3 <- lm(
  data = horan1971,
  post ~ 1 + experimental + prec
)

# summarize the non-centered model
summary(fit2)

# summarize the centered model
summary(fit3)
```

Other than the results for the intercept $\beta_0$, the results of the two versions of the ANCOVA model are identical. The ANCOVA point estimate for $\beta_1$ changed a lot from what we saw in the simple ANOVA model `fit1`. Once again, we can use the `tidy()` function to return the 95% confidence intervals in a nice format.

```{r}
tidy(fit3, conf.int = TRUE) %>% 
  slice(2) %>% 
  mutate_if(is.double, round, digits = 2)
```

Not only is the point estimate notably lower than in the simple ANOVA model, the confidence interval is much narrower. That change in the confidence interval width is a consequence of the much smaller standard error. It'll probably be easier to see this all in a coefficient plot.

```{r, fig.width = 6, fig.height = 1.5}
# wrangle
bind_rows(tidy(fit1, conf.int = TRUE), tidy(fit3, conf.int = TRUE)) %>% 
  filter(term == "experimental") %>% 
  mutate(model = factor(c("ANOVA", "ANCOVA"), levels = c("ANOVA", "ANCOVA"))) %>% 

  # plot!
  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = model)) +
  geom_vline(xintercept = 0, color = "white") +
  geom_pointrange() +
  scale_x_continuous(expression(beta[1]~(mu[experimental]-mu[waitlist])), expand = expansion(add = 5)) +
  ylab(NULL)
```

Even though the point estimates differ a lot between the ANOVA and ANCOVA models, the 95% interval for the ANOVA model completely overlaps the interval for the ANCOVA model. Both the ANOVA and ANCOVA models are known to produce unbiased estimates of the population parameters, but the ANCOVA model tends to produce estimates that are more precise. Thus if you have a high-quality baseline covariate laying around, it's a good idea to throw it into the model[^4].

## Recap

In this post, some of the main points we covered were:

* Two of the classical methods for analyzing 2-timepoint experimental data are
  - the ANOVA approach, where only the only predictor is the experimental group, and
  - the ANCOVA approach, where one adds one or more baseline covariates to the model.
* Although one could use a literal "analysis of [co]variance," you can also use OLS regression for both ANOVA- and ANCOVA-type models.
* Both approach are unbiased estimators of the population parameters.
* The ANCOVA approach is often more efficient, which is to say it often results is smaller standard errors and narrower confidence intervals.

For many of my readers, I imagine most of the material in this post was a review. But this material is designed to set the stage for the posts to come, and I hope at least some of the subsequent material will be more informative. Speaking of which, in the next post we'll analyze this data from a more causal inference perspective.

See you in the next one, friends!

## Session info

```{r}
sessionInfo()
```

## References

[^1]: I don't expect all my readers to know about the Premack principle, but it's well known among behaviorists and behavior therapists. In short, it states: *You can use high-probability behaviors to increase the frequency of low-probability behaviors*. Let's say you're a parent who's trying to get a stubborn child to eat their yucky vegetables (low-probability behavior). If you tell them "You can eat ice cream [a high-probability behavior] IF you eat all your vegetables," you have just used the Premack principle. If the child knows there's ice cream on the line (and presuming they like ice cream), they're more likely to eat those yucky vegetables. As you might imagine, there are all kinds of technical details I'm glossing over, here. If you'd like to learn more, a PhD in clinical psychology or behavior analysis might be a good fit for you.

[^2]: As discussed by @oConnell2017methods, the "ANOVA model" is a little ambiguous in that it can refer to using either `post` or `post - pre` as the dependent variable. If we were to use `post - pre`, this would be a change-score analysis. I'm not interested in going into a change-score discussion, here. In short, don't analyze change scores. I can understand why substantive researchers might find them interesting, but there are better alternatives.

[^3]: There are some contexts in which this is not the case. For example, if you're running a medical trial for which the primary outcome is mortality, all participants will necessarily be alive at baseline. So an important caveat is baseline measures tend to have strong correlations with post-intervention measures when they're of a continuous variable. Indeed, the distinction between continuous and binary variables is an important part of the story. But we're getting ahead of ourselves...

[^4]: Including baseline covariates is actually more than a "good idea." If you're running computer task experiments with undergrads, it probably doesn't matter much. But if you're running a clinical trial where lives are on the line, you want to use analytic strategies which are as unbiased and as precise as possible. When you're in the study-planning phase, the ANCOVA method can help you design a well-powered study with fewer participants, which could mean you'd be putting fewer participants lives at risk. I owe this insight to the great [Darren Dahly](https://twitter.com/statsepi).

```{r, eval = F, echo = F}
# wrangle
bind_rows(tidy(fit1, conf.int = TRUE), tidy(fit3, conf.int = TRUE)) %>% 
  filter(term == "experimental") %>% 
  mutate(model = factor(c("ANOVA", "ANCOVA"), levels = c("ANOVA", "ANCOVA"))) %>% 

  # plot!
  ggplot(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = model)) +
  geom_vline(xintercept = 0, color = "white") +
  geom_pointrange() +
  scale_x_continuous(expression(beta[1]~(mu[experimental]-mu[waitlist])), expand = expansion(add = 2)) +
  scale_y_discrete(expand = expansion(add = 2.5)) +
  labs(title = "Use your covariates!",
       subtitle = "Baseline covariates tend to shrink the\nstandard errors, for free.",
       y = NULL) +
  theme(axis.text.y = element_text(hjust = 0))

ggsave("baseline-covariates-featured.jpg", width = 3.6, height = 3.5, units = "in")
```
